{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360688d7",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc147268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257995</th>\n",
       "      <td>Carleigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257996</th>\n",
       "      <td>Iyana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257997</th>\n",
       "      <td>Kenley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257998</th>\n",
       "      <td>Sloane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257999</th>\n",
       "      <td>Elianna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           input\n",
       "0           John\n",
       "1        William\n",
       "2          James\n",
       "3        Charles\n",
       "4         George\n",
       "...          ...\n",
       "257995  Carleigh\n",
       "257996     Iyana\n",
       "257997    Kenley\n",
       "257998    Sloane\n",
       "257999   Elianna\n",
       "\n",
       "[258000 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://assets.datacamp.com/production/repositories/5286/datasets/45e193467da41ae7631b0d4d626c63d832a34cab/names.txt'\n",
    "names_df = pd.read_csv(url, header=None, names=['input'])\n",
    "names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d290b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a tab in front of all the names\n",
    "names_df['input'] = names_df['input'].apply(lambda x : '\\t' + x)\n",
    "\n",
    "# Append a newline at the end of every name\n",
    "# We already appended a tab in front, so the target word should start at index 1\n",
    "names_df['target'] = names_df['input'].apply(lambda x : x[1:len(x)] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f371f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(word_list):\n",
    "    char_set = set('\\n') # loop removes newline, add to set\n",
    "    for word in word_list:\n",
    "        for char in word:\n",
    "            char_set.add(char)\n",
    "    return char_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19af28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53}\n",
      "{0: '\\t', 1: '\\n', 2: 'A', 3: 'B', 4: 'C', 5: 'D', 6: 'E', 7: 'F', 8: 'G', 9: 'H', 10: 'I', 11: 'J', 12: 'K', 13: 'L', 14: 'M', 15: 'N', 16: 'O', 17: 'P', 18: 'Q', 19: 'R', 20: 'S', 21: 'T', 22: 'U', 23: 'V', 24: 'W', 25: 'X', 26: 'Y', 27: 'Z', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary\n",
    "vocabulary = get_vocabulary(names_df['input'])\n",
    "\n",
    "# Sort the vocabulary\n",
    "vocabulary_sorted = sorted(vocabulary)\n",
    "\n",
    "# Create the mapping of the vocabulary chars to integers\n",
    "char_to_idx = { char : idx for idx, char in enumerate(vocabulary_sorted) }\n",
    "\n",
    "# Create the mapping of the integers to vocabulary chars\n",
    "idx_to_char = { idx : char for idx, char in enumerate(vocabulary_sorted) }\n",
    "\n",
    "# Print the dictionaries\n",
    "print(char_to_idx)\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794fde07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_len(words):\n",
    "    return max([len(word) for word in words])\n",
    "    \n",
    "get_max_len(['1', '12', '\\t234\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c0f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce60cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of longest name\n",
    "max_len = get_max_len(names_df['input'])\n",
    "\n",
    "# Initialize the input vector\n",
    "input_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Initialize the target vector\n",
    "target_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac6b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((258000, 13, 54), (258000, 13, 54))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I thought target would be a single character\n",
    "input_data.shape, target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401376b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['input']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    input_data[n_idx, c_idx, char_to_idx[char]] = 1\n",
    "\n",
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['target']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    target_data[n_idx, c_idx, char_to_idx[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d775ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, TimeDistributed, Dense\n",
    "\n",
    "# The model build would not work until I downgraded to numpy\n",
    "# cond install numpy=1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33b6079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 13, 50)            5250      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 13, 54)            2754      \n",
      "=================================================================\n",
      "Total params: 8,004\n",
      "Trainable params: 8,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add SimpleRNN layer of 50 units\n",
    "model.add(SimpleRNN(50, input_shape=(max_len+1, len(vocabulary)), return_sequences=True))\n",
    "\n",
    "# Add a TimeDistributed Dense layer of size same as the vocabulary\n",
    "model.add(TimeDistributed(Dense(len(vocabulary), activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e07627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2016/2016 [==============================] - 56s 27ms/step - loss: 1.2902\n",
      "Epoch 2/5\n",
      "2016/2016 [==============================] - 52s 26ms/step - loss: 1.0155\n",
      "Epoch 3/5\n",
      "2016/2016 [==============================] - 50s 25ms/step - loss: 0.9710\n",
      "Epoch 4/5\n",
      "2016/2016 [==============================] - 61s 30ms/step - loss: 0.9448\n",
      "Epoch 5/5\n",
      "2016/2016 [==============================] - 70s 35ms/step - loss: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feabbf2f250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model for 5 epochs using a batch size of 128 \n",
    "model.fit(input_data, target_data, batch_size=128, epochs=5)\n",
    "\n",
    "# Create a 3-D zero vector and initialize it with the start token\n",
    "output_seq = np.zeros((1, max_len+1, len(vocabulary)))\n",
    "output_seq[0, 0, char_to_idx['\\t']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5fcda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3-D zero vector and initialize it with the start token\n",
    "output_seq = np.zeros((1, max_len+1, len(vocabulary)))\n",
    "output_seq[0, 0, char_to_idx['\\t']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e09933e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosullivan/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# Get the probabilities for the first character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,1,:]\n",
    "\n",
    "# Sample vocabulary to get first character\n",
    "first_char = np.random.choice(sorted(vocabulary), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "\n",
    "# Print the character generated\n",
    "print(first_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "935b2f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "# Print the first character which we got last time\n",
    "print(first_char)\n",
    "\n",
    "# Update the vector to contain first the character\n",
    "output_seq[0, 1, char_to_idx[first_char]] = 1\n",
    "\n",
    "# Get the probabilities for the second character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,2,:]\n",
    "\n",
    "# Sample vocabulary to get second character\n",
    "second_char = np.random.choice(sorted(vocabulary), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "\n",
    "# Print the second character\n",
    "print(second_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ba546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probabilities for the second character\n",
    "probs = model.predict_proba(output_seq, verbose=0)[:,2,:]\n",
    "\n",
    "# Sample vocabulary to get second character\n",
    "second_char = np.random.choice(sorted(vocabulary), replace=False, p=probs.reshape(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c795b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baby_names(n):\n",
    "    # return n baby names\n",
    "    for i in range(n):\n",
    "        stop = False\n",
    "        counter = 1\n",
    "        name = ''\n",
    "        # Create a 3-D zero vector and initialize it with the start token\n",
    "        output_seq = np.zeros((1, max_len+1, len(vocabulary)))\n",
    "        output_seq[0, 0, char_to_idx['\\t']] = 1\n",
    "        while not stop and counter < 10:\n",
    "            # Get the probabilities for the next character\n",
    "            probs = model.predict_proba(output_seq, verbose=0)[:,counter-1,:]\n",
    "            c = np.random.choice(sorted(vocabulary), replace=False, p=probs.reshape(len(vocabulary)))\n",
    "            if c == '\\n':\n",
    "                stop = True\n",
    "            else:\n",
    "                name = name + c\n",
    "                output_seq[0, counter, char_to_idx[c]] = 1\n",
    "                counter = counter + 1\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_baby_names(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
