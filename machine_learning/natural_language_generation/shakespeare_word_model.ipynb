{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a5724e",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "One disadvantage of the neural network courses is they run from very old versions. So following along in a local notebook is a painful experience of errors, followed by downgrade detective work. This doesn't work with tensorflow 2.\n",
    "\n",
    "Instead I create a new conda env called tensorflow v1 and python 3.6:\n",
    "<pre>\n",
    "conda create -n tensorflow\n",
    "conda activate tensorflow\n",
    "conda install py=3.6\n",
    "conda install tensorflow=1\n",
    "conda install jupyter ipykernel pandas keras matplotlib\n",
    "</pre>\n",
    "\n",
    "You then need to create a new kernel that uses this environment:\n",
    "<pre>\n",
    "conda activate tensorflow\n",
    "python -m ipykernel install --user --name tensorflow --display-name tensorflow\n",
    "</pre>\n",
    "\n",
    "Then you can pick or change the kernel in Jupyter by reloading the page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c633a5c",
   "metadata": {},
   "source": [
    "## Word Model\n",
    "If I remove punctuation and new lines, and lower case text. How many words do I have? Run the model with this anyway, but if the results are poor, then tokenise but leave the stop words in. I need those for a sentence to make sense.\n",
    "\n",
    "### Raw Lower Case Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c030f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "url = 'https://assets.datacamp.com/production/repositories/5286/datasets/2b130693c9bd45c528b60fa9efbf5148a3ff14e5/shakespear.txt'\n",
    "file = 'shakespear.txt'\n",
    "\n",
    "#urlretrieve(url, file)\n",
    "\n",
    "text = ''\n",
    "with open(file, 'r') as f:\n",
    "    text = f.read()\n",
    "    text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4465c3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3508"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove anything that isn't a space or lower case letter.\n",
    "no_nl_text = re.sub('\\n', ' ', text)\n",
    "no_nl_text = re.sub('  ', ' ', no_nl_text)\n",
    "no_nl_text = re.sub('\\.', ' .', no_nl_text)\n",
    "just_words = re.sub('[^a-z .]+', '', no_nl_text)\n",
    "\n",
    "vocabulary = set(just_words.split())\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d812f",
   "metadata": {},
   "source": [
    "That is a lot - the character set was 36 columns as OHE. Let's do some quick analysis of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ae9e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume a sentence ends in a dot\n",
    "sentences = just_words.split('.')\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f05526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.263843648208468, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split each sentence into words and count\n",
    "sentence_length = [len(line.split()) for line in sentences]\n",
    "\n",
    "# mean and median sentence length\n",
    "sum(sentence_length)/len(sentence_length), sorted(sentence_length)[round(len(sentence_length)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3687850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the distribution of words per sentence\n",
    "plt.hist(sentence_length, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf2a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shakespear is an extreme case of sentence variation\n",
    "# But let's start with the median as our max sequence length\n",
    "# because our vocab is 120 times bigger\n",
    "maxlen = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d718f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# remove the 20 most common words\n",
    "text = just_words.split()\n",
    "top_n = 100\n",
    "stop_words = Counter(text).most_common()[:top_n]\n",
    "stop_words = [word for word, count in stop_words]\n",
    "text = [word for word in text if word not in stop_words]\n",
    "vocabulary = set(text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684ce487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Sequences: 8422\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(text)\n",
    "\n",
    "# Dictionary to save the mapping from char to integer\n",
    "word_to_idx = { word : idx for idx, word in enumerate(vocabulary) }\n",
    "\n",
    "# Dictionary to save the mapping from integer to char\n",
    "idx_to_word = { idx : word for idx, word in enumerate(vocabulary) }\n",
    "\n",
    "# Create empty lists for input and target dataset\n",
    "input_data = []\n",
    "target_data = []\n",
    "\n",
    "# Iterate to get all substrings of length maxlen\n",
    "for i in range(0, len(text) - maxlen):\n",
    "    # Find the sequence of length maxlen starting at i\n",
    "    input_data.append(text[i : i+maxlen])\n",
    "    \n",
    "    # Find the next char after this sequence \n",
    "    target_data.append(text[i+maxlen])\n",
    "\n",
    "# Print number of sequences in input data\n",
    "print('No of Sequences:', len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf444b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['contempt',\n",
       "  'claimd',\n",
       "  'slept',\n",
       "  'faithful',\n",
       "  'contrive',\n",
       "  'father',\n",
       "  'defeated',\n",
       "  'queen',\n",
       "  'flesh',\n",
       "  'broke',\n",
       "  'puttance',\n",
       "  'expedition',\n",
       "  'house',\n",
       "  'same',\n",
       "  'ever',\n",
       "  'lament',\n",
       "  'stomach',\n",
       "  'nor',\n",
       "  'butly',\n",
       "  'fury',\n",
       "  'knowing',\n",
       "  'everything',\n",
       "  'grew',\n",
       "  'daily',\n",
       "  'ever',\n",
       "  'great',\n",
       "  'strength',\n",
       "  'thought',\n",
       "  'bright',\n",
       "  'buds',\n",
       "  'mine',\n",
       "  'own',\n",
       "  'biondello',\n",
       "  'marry',\n",
       "  'pray',\n",
       "  'patience',\n",
       "  'lear',\n",
       "  'instant',\n",
       "  'common',\n",
       "  'maid'],\n",
       " 'less')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[1], target_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590a980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3-D zero vector to contain the encoded input sequences\n",
    "x = np.zeros((len(input_data), maxlen, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Create a 2-D zero vector to contain the encoded target characters\n",
    "y = np.zeros((len(target_data), len(vocabulary)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "508a7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the sequences\n",
    "for s_idx, sequence in enumerate(input_data):\n",
    "    # Iterate over all characters in the sequence\n",
    "    for idx, word in enumerate(sequence):\n",
    "        # Fill up vector x\n",
    "        x[s_idx, idx, word_to_idx[word]] = 1    \n",
    "    # Fill up vector y\n",
    "    y[s_idx, word_to_idx[target_data[s_idx]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feee5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bosullivan/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/bosullivan/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6737 samples, validate on 1685 samples\n",
      "Epoch 1/1\n",
      "6737/6737 [==============================] - 15s 2ms/step - loss: 8.0276 - val_loss: 8.0024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff348f18198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sequential model \n",
    "model = Sequential()\n",
    "\n",
    "# Add an LSTM layer of 128 units\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(vocabulary))))\n",
    "\n",
    "# Add a Dense output layer\n",
    "model.add(Dense(len(vocabulary), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x, y, batch_size=64, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2978646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_sent(sentence):\n",
    "    text = sentence.lower()\n",
    "    text = re.sub('[^a-z ]+','', text)\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def remove_stop(words):\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "\n",
    "def repeat(sentence):\n",
    "    words = sentence.split()\n",
    "    res = False\n",
    "    if len(set(words[-10:])) < 9:\n",
    "        res = True\n",
    "    elif len(set(words[-2:])) == 1:\n",
    "        res = True\n",
    "    elif len(set(words[-5:])) < 4:\n",
    "        res = True\n",
    "    return res\n",
    "\n",
    "\n",
    "def random(preds):\n",
    "    top_n = round(len(vocabulary)**0.5)\n",
    "    top_preds = preds.argsort()[- top_n-5:-5]\n",
    "    idx = np.random.choice(top_preds)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def generate_text(sentence, no_words):\n",
    "    maxlen = 40\n",
    "    text = clean_sent(sentence)\n",
    "    text = remove_stop(text)\n",
    "    for i in range(no_words):\n",
    "        text = text[i:maxlen+i]\n",
    "        X_test = np.zeros((1, maxlen, len(vocabulary)))\n",
    "        for s_idx, word in enumerate(text):\n",
    "            X_test[0, s_idx, word_to_idx[word]] = 1\n",
    "        preds_next_word = model.predict(X_test)[0]\n",
    "        if repeat(sentence):\n",
    "            idx = random(preds_next_word)\n",
    "        else:\n",
    "            idx = np.argmax(preds_next_word)\n",
    "        next_word = idx_to_word[idx]\n",
    "        sentence += ' ' + next_word\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69dc91f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that, poor contempt, or claim'd thou sleep cause can every every john every tis great any master been john before wife every every doth every john hand master very who tis without every every could every doth\n"
     ]
    }
   ],
   "source": [
    "# Input sequence and generate text\n",
    "sentence = \"that, poor contempt, or claim'd thou sleep\"\n",
    "print(generate_text(sentence, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8598412",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye other ground likey queen elizabeth each choked whiles nature between fanny little fault lightly read thus wellmet whiles been son blind damned bonds citizen removed cannot speak host loath amazedgo parted hands marshally vile haste noble hand used naked\n",
      "eye other ground likey queen elizabeth each choked whiles nature between fanny little fault lightly read thus wellmet whiles been son blind damned bonds citizen removed cannot speak host loath amazedgo parted hands marshally vile haste noble hand used naked every every very every bloody even heart husband doth could\n",
      "\n",
      "tremble has privilege creatures citizens plain cur measure goodness gods romery doe breastbold flatterers esemble sun condemnd myill oclock sensual being deep easy welled search gloss leaven vincentio followo issue friends up lady silent offences clother appear prince henry pray\n",
      "tremble has privilege creatures citizens plain cur measure goodness gods romery doe breastbold flatterers esemble sun condemnd myill oclock sensual being deep easy welled search gloss leaven vincentio followo issue friends up lady silent offences clother appear prince henry pray every every death every where john john cause tis made\n",
      "\n",
      "news blush pun haste loss calld short summer grief whose truly bait dost better moonshine stayd against noble dry since great tower though affections leaved any browly wind way julius clock throws up speak within power hundred life tender study\n",
      "news blush pun haste loss calld short summer grief whose truly bait dost better moonshine stayd against noble dry since great tower though affections leaved any browly wind way julius clock throws up speak within power hundred life tender study every every think every too men never doth art hand\n",
      "\n",
      "lets away toby belch kingdom mighty fellow said tis half rutland smiles shrewsbury rosalind never heared gracious lady needs infant correction shalt marry came down katharina duching succeeding hotspur art full thine aeneas any fat court poetry shouldst consequence being\n",
      "lets away toby belch kingdom mighty fellow said tis half rutland smiles shrewsbury rosalind never heared gracious lady needs infant correction shalt marry came down katharina duching succeeding hotspur art full thine aeneas any fat court poetry shouldst consequence being every every great every till tis hand mine till been\n",
      "\n",
      "hear daughter drop moon fement extempority seem sight norfolk live such ground tongue brief fire tend particular due mercy remain john gaunt rid haild dispose two miles before hast worth compexaration city fly ferminence lies honourable higher same chain request\n",
      "hear daughter drop moon fement extempority seem sight norfolk live such ground tongue brief fire tend particular due mercy remain john gaunt rid haild dispose two miles before hast worth compexaration city fly ferminence lies honourable higher same chain request every every two every think till doth life life nor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pick random maxlen snippets\n",
    "for _ in range(5):\n",
    "    max_words = len(text)\n",
    "    idx = round(np.random.uniform()*(max_words-maxlen))\n",
    "    sentence = ' '.join(text[idx:idx+maxlen])\n",
    "    new = generate_text(sentence, 10)\n",
    "    print(sentence + '\\n' + new + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff027f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a class\n",
    "# get data\n",
    "# clean data\n",
    "# vectorize data\n",
    "# run model\n",
    "# generate text\n",
    "# score generated text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4c31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
