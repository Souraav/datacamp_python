{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Churn - Fast Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      "satisfaction            14999 non-null float64\n",
      "evaluation              14999 non-null float64\n",
      "number_of_projects      14999 non-null int64\n",
      "average_montly_hours    14999 non-null int64\n",
      "time_spend_company      14999 non-null int64\n",
      "work_accident           14999 non-null int64\n",
      "churn                   14999 non-null int64\n",
      "promotion               14999 non-null int64\n",
      "department              14999 non-null object\n",
      "salary                  14999 non-null object\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "file = 'turnover.csv'\n",
    "url  = 'https://assets.datacamp.com/production/course_6221/datasets/' + file\n",
    "urlretrieve(url, file)\n",
    "hr_df = pd.read_csv(file)\n",
    "hr_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['department', 'salary']\n",
    "for col in cat_cols:\n",
    "    hr_df[col] = hr_df[col].astype('category')\n",
    "\n",
    "X = pd.get_dummies(hr_df.drop('churn', axis='columns'))\n",
    "y = hr_df.churn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11249, 20), (3750, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score:  0.7941333333333334\n",
      "F1 Score:  0.4340175953079179\n",
      "[[2682  186]\n",
      " [ 586  296]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Model Score: \", clf.score(X_test, y_test))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score:  0.9904\n",
      "F1 Score:  0.979310344827586\n",
      "[[2862    6]\n",
      " [  30  852]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Brian/anaconda3/envs/datacamp/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Random model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Model Score: \", clf.score(X_test, y_test))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.904880 using {'batch_size': 5, 'epochs': 15, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.781136 (0.042954) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.761934 (0.003740) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.832785 (0.025148) with: {'batch_size': 5, 'epochs': 5, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.831452 (0.037644) with: {'batch_size': 5, 'epochs': 5, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.855632 (0.015386) with: {'batch_size': 5, 'epochs': 5, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.791270 (0.047921) with: {'batch_size': 5, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.664504 (0.299629) with: {'batch_size': 5, 'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.810116 (0.066414) with: {'batch_size': 5, 'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.902036 (0.005230) with: {'batch_size': 5, 'epochs': 10, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.866477 (0.030160) with: {'batch_size': 5, 'epochs': 10, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.874122 (0.029616) with: {'batch_size': 5, 'epochs': 10, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.877234 (0.025552) with: {'batch_size': 5, 'epochs': 10, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.690639 (0.317887) with: {'batch_size': 5, 'epochs': 15, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.866299 (0.047264) with: {'batch_size': 5, 'epochs': 15, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.904880 (0.005049) with: {'batch_size': 5, 'epochs': 15, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.884968 (0.023083) with: {'batch_size': 5, 'epochs': 15, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.853498 (0.068459) with: {'batch_size': 5, 'epochs': 15, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.891457 (0.006652) with: {'batch_size': 5, 'epochs': 15, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.787448 (0.029205) with: {'batch_size': 10, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.800960 (0.046811) with: {'batch_size': 10, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.827896 (0.014381) with: {'batch_size': 10, 'epochs': 5, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.789315 (0.044525) with: {'batch_size': 10, 'epochs': 5, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.768424 (0.014999) with: {'batch_size': 10, 'epochs': 5, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.855009 (0.007599) with: {'batch_size': 10, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.881945 (0.004913) with: {'batch_size': 10, 'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.817762 (0.041643) with: {'batch_size': 10, 'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.870922 (0.012750) with: {'batch_size': 10, 'epochs': 10, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.840164 (0.048664) with: {'batch_size': 10, 'epochs': 10, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.845853 (0.057907) with: {'batch_size': 10, 'epochs': 10, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.889679 (0.010478) with: {'batch_size': 10, 'epochs': 10, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.803716 (0.054920) with: {'batch_size': 10, 'epochs': 15, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.767090 (0.008359) with: {'batch_size': 10, 'epochs': 15, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.894213 (0.009124) with: {'batch_size': 10, 'epochs': 15, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.902658 (0.007932) with: {'batch_size': 10, 'epochs': 15, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.890479 (0.020329) with: {'batch_size': 10, 'epochs': 15, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.887546 (0.007304) with: {'batch_size': 10, 'epochs': 15, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.762646 (0.004343) with: {'batch_size': 20, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.778025 (0.021468) with: {'batch_size': 20, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.770024 (0.011484) with: {'batch_size': 20, 'epochs': 5, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.756601 (0.008738) with: {'batch_size': 20, 'epochs': 5, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.779892 (0.024078) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.760957 (0.004495) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.588408 (0.245566) with: {'batch_size': 20, 'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.805405 (0.026898) with: {'batch_size': 20, 'epochs': 10, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.872255 (0.033463) with: {'batch_size': 20, 'epochs': 10, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.818117 (0.036006) with: {'batch_size': 20, 'epochs': 10, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.836608 (0.022618) with: {'batch_size': 20, 'epochs': 10, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.891813 (0.007751) with: {'batch_size': 20, 'epochs': 10, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.850120 (0.027462) with: {'batch_size': 20, 'epochs': 15, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.796515 (0.030707) with: {'batch_size': 20, 'epochs': 15, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.880167 (0.020069) with: {'batch_size': 20, 'epochs': 15, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.904436 (0.014835) with: {'batch_size': 20, 'epochs': 15, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.863366 (0.019030) with: {'batch_size': 20, 'epochs': 15, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.899369 (0.012952) with: {'batch_size': 20, 'epochs': 15, 'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.activations import relu, softmax, sigmoid\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=20, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=20, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "# This takes nearly 4 hours...\n",
    "# smallest batch, largest epoch's (no surprise) - but interesting\n",
    "# normal init, and rmsprop optimizer (rather than adam). \n",
    "# Best: 0.904880 using {'batch_size': 5, 'epochs': 15, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "inits = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [5, 10, 15]\n",
    "batches = [5, 10, 20]\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train_np, y_train_np)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11249/11249 [==============================] - 32s 3ms/step - loss: 0.5494 - acc: 0.7610\n",
      "Epoch 2/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.4552 - acc: 0.7654\n",
      "Epoch 3/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.3995 - acc: 0.8080\n",
      "Epoch 4/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.3364 - acc: 0.8602\n",
      "Epoch 5/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.3065 - acc: 0.8758\n",
      "Epoch 6/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.2975 - acc: 0.8825\n",
      "Epoch 7/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.2965 - acc: 0.8840\n",
      "Epoch 8/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.2994 - acc: 0.8833\n",
      "Epoch 9/25\n",
      "11249/11249 [==============================] - 19s 2ms/step - loss: 0.2973 - acc: 0.8899\n",
      "Epoch 10/25\n",
      "11249/11249 [==============================] - 17s 2ms/step - loss: 0.2957 - acc: 0.8875\n",
      "Epoch 11/25\n",
      "11249/11249 [==============================] - 17s 2ms/step - loss: 0.3013 - acc: 0.8871\n",
      "Epoch 12/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.2941 - acc: 0.8913\n",
      "Epoch 13/25\n",
      "11249/11249 [==============================] - 17s 2ms/step - loss: 0.3004 - acc: 0.8930\n",
      "Epoch 14/25\n",
      "11249/11249 [==============================] - 19s 2ms/step - loss: 0.2950 - acc: 0.8945\n",
      "Epoch 15/25\n",
      "11249/11249 [==============================] - 17s 2ms/step - loss: 0.2934 - acc: 0.8954\n",
      "Epoch 16/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.2935 - acc: 0.8961\n",
      "Epoch 17/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.2879 - acc: 0.8970\n",
      "Epoch 18/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.2829 - acc: 0.9019\n",
      "Epoch 19/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.2808 - acc: 0.9047\n",
      "Epoch 20/25\n",
      "11249/11249 [==============================] - 19s 2ms/step - loss: 0.2827 - acc: 0.9000\n",
      "Epoch 21/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.2725 - acc: 0.9075\n",
      "Epoch 22/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.2756 - acc: 0.9061\n",
      "Epoch 23/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.2727 - acc: 0.9104\n",
      "Epoch 24/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.2686 - acc: 0.9081\n",
      "Epoch 25/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.2694 - acc: 0.9083\n",
      "11249/11249 [==============================] - 8s 688us/step\n",
      "[0.31072746631804865, 0.8902124633300738]\n",
      "F1 Score:  0.7553699284009547\n",
      "[[2707  161]\n",
      " [ 249  633]]\n"
     ]
    }
   ],
   "source": [
    "# Use best hyper-parameters - increase epoch\n",
    "model = create_model(init='uniform')\n",
    "model.fit(X_train_np, y_train_np, epochs=25, batch_size=5)\n",
    "y_pred = (model.predict(X_test_np) > 0.5)\n",
    "\n",
    "print(model.evaluate(X_train_np, y_train_np))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11249/11249 [==============================] - 24s 2ms/step - loss: 0.5291 - acc: 0.7606\n",
      "Epoch 2/25\n",
      "11249/11249 [==============================] - 19s 2ms/step - loss: 0.4403 - acc: 0.7753\n",
      "Epoch 3/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.3870 - acc: 0.8054\n",
      "Epoch 4/25\n",
      "11249/11249 [==============================] - 20s 2ms/step - loss: 0.3497 - acc: 0.8346\n",
      "Epoch 5/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.3286 - acc: 0.8573\n",
      "Epoch 6/25\n",
      "11249/11249 [==============================] - 19s 2ms/step - loss: 0.3154 - acc: 0.8691\n",
      "Epoch 7/25\n",
      "11249/11249 [==============================] - 18s 2ms/step - loss: 0.3095 - acc: 0.8700\n",
      "Epoch 8/25\n",
      "11249/11249 [==============================] - 19s 2ms/step - loss: 0.3017 - acc: 0.8779\n",
      "Epoch 9/25\n",
      "11249/11249 [==============================] - 21s 2ms/step - loss: 0.3016 - acc: 0.8795\n",
      "Epoch 10/25\n",
      "11249/11249 [==============================] - 23s 2ms/step - loss: 0.2957 - acc: 0.8812\n",
      "Epoch 11/25\n",
      "11249/11249 [==============================] - 22s 2ms/step - loss: 0.2972 - acc: 0.8805\n",
      "Epoch 12/25\n",
      "11249/11249 [==============================] - 23s 2ms/step - loss: 0.2918 - acc: 0.8852\n",
      "Epoch 13/25\n",
      " 4005/11249 [=========>....................] - ETA: 14s - loss: 0.2912 - acc: 0.8864"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import normal\n",
    "\n",
    "def create_model(optimizer='rmsprop', init='normal'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=20, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# explore tensorboard of a very simple model\n",
    "from keras.callbacks import TensorBoard\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "            batch_size=32, write_graph=True,\n",
    "            write_grads=False, write_images=False,\n",
    "            embeddings_freq=0, embeddings_layer_names=None,\n",
    "            embeddings_metadata=None, embeddings_data=None)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(X_train_np, y_train_np, epochs=25, batch_size=5, callbacks=[tb])\n",
    "y_pred = (model.predict(X_test_np) > 0.5)\n",
    "\n",
    "print(model.evaluate(X_train_np, y_train_np))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
