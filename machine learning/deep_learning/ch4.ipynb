{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data prep\n",
    "file = 'titanic_all_numeric.csv'\n",
    "df = pd.read_csv(file)\n",
    "predictors = df.drop('survived', axis='columns').as_matrix()\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "input_shape = (10, )\n",
    "\n",
    "def get_new_model(input_shape = input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 746us/step - loss: 1.1689 - acc: 0.4928 - val_loss: 1.4055 - val_acc: 0.4627\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 180us/step - loss: 1.1608 - acc: 0.4767 - val_loss: 1.3988 - val_acc: 0.4590\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 215us/step - loss: 1.1535 - acc: 0.4799 - val_loss: 1.3915 - val_acc: 0.4552\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 152us/step - loss: 1.1456 - acc: 0.4783 - val_loss: 1.3849 - val_acc: 0.4552\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 149us/step - loss: 1.1385 - acc: 0.4751 - val_loss: 1.3784 - val_acc: 0.4440\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 153us/step - loss: 1.1314 - acc: 0.4735 - val_loss: 1.3720 - val_acc: 0.4440\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 154us/step - loss: 1.1243 - acc: 0.4735 - val_loss: 1.3656 - val_acc: 0.4440\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 170us/step - loss: 1.1174 - acc: 0.4687 - val_loss: 1.3591 - val_acc: 0.4440\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 162us/step - loss: 1.1107 - acc: 0.4687 - val_loss: 1.3522 - val_acc: 0.4440\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 183us/step - loss: 1.1038 - acc: 0.4687 - val_loss: 1.3458 - val_acc: 0.4403\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 694us/step - loss: 1.7704 - acc: 0.5795 - val_loss: 1.0089 - val_acc: 0.7276\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 143us/step - loss: 1.0153 - acc: 0.6292 - val_loss: 0.6769 - val_acc: 0.5821\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 147us/step - loss: 0.8240 - acc: 0.6100 - val_loss: 0.5761 - val_acc: 0.7201\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 169us/step - loss: 0.6540 - acc: 0.6581 - val_loss: 0.6330 - val_acc: 0.6716\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 142us/step - loss: 0.6772 - acc: 0.6485 - val_loss: 0.5906 - val_acc: 0.6940\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 144us/step - loss: 0.6537 - acc: 0.6613 - val_loss: 0.6327 - val_acc: 0.7127\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 152us/step - loss: 0.6271 - acc: 0.6501 - val_loss: 0.5889 - val_acc: 0.7052\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 180us/step - loss: 0.6947 - acc: 0.6164 - val_loss: 0.5388 - val_acc: 0.7388\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 202us/step - loss: 0.6201 - acc: 0.6677 - val_loss: 0.5257 - val_acc: 0.7388\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 244us/step - loss: 0.6048 - acc: 0.6870 - val_loss: 0.7027 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 689us/step - loss: 6.4016 - acc: 0.5923 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 145us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 122us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 146us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 150us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 143us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 174us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 198us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 208us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 229us/step - loss: 6.3644 - acc: 0.6051 - val_loss: 5.7736 - val_acc: 0.6418\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target, epochs=10, validation_split=0.3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "Nifty option in fit to split train/test model.fit(<blah>, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 0.8921 - acc: 0.6116 - val_loss: 0.7886 - val_acc: 0.6157\n",
      "Epoch 2/100\n",
      "623/623 [==============================] - 0s 196us/step - loss: 0.7894 - acc: 0.6292 - val_loss: 0.6395 - val_acc: 0.6866\n",
      "Epoch 3/100\n",
      "623/623 [==============================] - 0s 156us/step - loss: 0.6557 - acc: 0.6693 - val_loss: 0.7255 - val_acc: 0.6418\n",
      "Epoch 4/100\n",
      "623/623 [==============================] - 0s 160us/step - loss: 0.6004 - acc: 0.6854 - val_loss: 0.5353 - val_acc: 0.7276\n",
      "Epoch 5/100\n",
      "623/623 [==============================] - 0s 213us/step - loss: 0.5629 - acc: 0.7014 - val_loss: 0.4996 - val_acc: 0.7388\n",
      "Epoch 6/100\n",
      "623/623 [==============================] - 0s 320us/step - loss: 0.5725 - acc: 0.7143 - val_loss: 0.4912 - val_acc: 0.7425\n",
      "Epoch 7/100\n",
      "623/623 [==============================] - 0s 229us/step - loss: 0.6647 - acc: 0.6918 - val_loss: 0.4925 - val_acc: 0.7836\n",
      "Epoch 8/100\n",
      "623/623 [==============================] - 0s 222us/step - loss: 0.6071 - acc: 0.6966 - val_loss: 0.5944 - val_acc: 0.7052\n",
      "Epoch 9/100\n",
      "623/623 [==============================] - 0s 228us/step - loss: 0.5582 - acc: 0.7303 - val_loss: 0.4987 - val_acc: 0.7425\n",
      "Epoch 10/100\n",
      "623/623 [==============================] - 0s 198us/step - loss: 0.5406 - acc: 0.7239 - val_loss: 0.5139 - val_acc: 0.7313\n",
      "Epoch 11/100\n",
      "623/623 [==============================] - 0s 184us/step - loss: 0.6506 - acc: 0.6838 - val_loss: 0.4581 - val_acc: 0.7612\n",
      "Epoch 12/100\n",
      "623/623 [==============================] - 0s 201us/step - loss: 0.6139 - acc: 0.7175 - val_loss: 0.5893 - val_acc: 0.7649\n",
      "Epoch 13/100\n",
      "623/623 [==============================] - 0s 196us/step - loss: 0.5561 - acc: 0.7287 - val_loss: 0.4912 - val_acc: 0.7948\n",
      "Epoch 14/100\n",
      "623/623 [==============================] - 0s 206us/step - loss: 0.5158 - acc: 0.7737 - val_loss: 0.4709 - val_acc: 0.8172\n",
      "Epoch 15/100\n",
      "623/623 [==============================] - 0s 231us/step - loss: 0.5372 - acc: 0.7400 - val_loss: 0.5643 - val_acc: 0.7687\n",
      "Epoch 16/100\n",
      "623/623 [==============================] - 0s 240us/step - loss: 0.5093 - acc: 0.7753 - val_loss: 0.4505 - val_acc: 0.8060\n",
      "Epoch 17/100\n",
      "623/623 [==============================] - 0s 170us/step - loss: 0.4938 - acc: 0.7721 - val_loss: 0.4351 - val_acc: 0.7985\n",
      "Epoch 18/100\n",
      "623/623 [==============================] - 0s 172us/step - loss: 0.6171 - acc: 0.7030 - val_loss: 0.4563 - val_acc: 0.7649\n",
      "Epoch 19/100\n",
      "623/623 [==============================] - 0s 177us/step - loss: 0.5242 - acc: 0.7721 - val_loss: 0.4939 - val_acc: 0.7836\n",
      "Epoch 20/100\n",
      "623/623 [==============================] - 0s 167us/step - loss: 0.5832 - acc: 0.7416 - val_loss: 0.4629 - val_acc: 0.7687\n",
      "Epoch 21/100\n",
      "623/623 [==============================] - 0s 168us/step - loss: 0.5810 - acc: 0.7464 - val_loss: 0.5517 - val_acc: 0.7649\n",
      "Epoch 22/100\n",
      "623/623 [==============================] - 0s 215us/step - loss: 0.5113 - acc: 0.7576 - val_loss: 0.4338 - val_acc: 0.8022\n",
      "Epoch 23/100\n",
      "623/623 [==============================] - 0s 243us/step - loss: 0.4932 - acc: 0.7785 - val_loss: 0.5422 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      "623/623 [==============================] - 0s 298us/step - loss: 0.5292 - acc: 0.7769 - val_loss: 0.4379 - val_acc: 0.7910\n",
      "Epoch 25/100\n",
      "623/623 [==============================] - 0s 251us/step - loss: 0.4996 - acc: 0.7657 - val_loss: 0.4141 - val_acc: 0.8097\n",
      "Epoch 26/100\n",
      "623/623 [==============================] - 0s 260us/step - loss: 0.5040 - acc: 0.7978 - val_loss: 0.5554 - val_acc: 0.7724\n",
      "Epoch 27/100\n",
      "623/623 [==============================] - 0s 246us/step - loss: 0.5373 - acc: 0.7865 - val_loss: 0.4515 - val_acc: 0.8097\n",
      "Epoch 28/100\n",
      "623/623 [==============================] - 0s 240us/step - loss: 0.4892 - acc: 0.7624 - val_loss: 0.4600 - val_acc: 0.7836\n",
      "Epoch 29/100\n",
      "623/623 [==============================] - 0s 275us/step - loss: 0.4707 - acc: 0.7849 - val_loss: 0.4217 - val_acc: 0.8060\n",
      "Epoch 30/100\n",
      "623/623 [==============================] - 0s 268us/step - loss: 0.4640 - acc: 0.7881 - val_loss: 0.4309 - val_acc: 0.8060\n",
      "Epoch 31/100\n",
      "623/623 [==============================] - 0s 192us/step - loss: 0.4840 - acc: 0.7801 - val_loss: 0.4516 - val_acc: 0.8134\n",
      "Epoch 32/100\n",
      "623/623 [==============================] - 0s 179us/step - loss: 0.4675 - acc: 0.7945 - val_loss: 0.5382 - val_acc: 0.7687\n",
      "Epoch 33/100\n",
      "623/623 [==============================] - 0s 187us/step - loss: 0.5222 - acc: 0.7865 - val_loss: 0.4741 - val_acc: 0.7948\n",
      "Epoch 34/100\n",
      "623/623 [==============================] - 0s 194us/step - loss: 0.5235 - acc: 0.7737 - val_loss: 0.4957 - val_acc: 0.7761\n",
      "Epoch 35/100\n",
      "623/623 [==============================] - 0s 195us/step - loss: 0.4682 - acc: 0.7897 - val_loss: 0.4430 - val_acc: 0.8097\n",
      "Epoch 36/100\n",
      "623/623 [==============================] - 0s 213us/step - loss: 0.4631 - acc: 0.7865 - val_loss: 0.4489 - val_acc: 0.8022\n",
      "Epoch 37/100\n",
      "623/623 [==============================] - 0s 214us/step - loss: 0.4680 - acc: 0.7961 - val_loss: 0.4808 - val_acc: 0.8209\n",
      "Epoch 38/100\n",
      "623/623 [==============================] - 0s 185us/step - loss: 0.5671 - acc: 0.7657 - val_loss: 0.4126 - val_acc: 0.8172\n",
      "Epoch 39/100\n",
      "623/623 [==============================] - 0s 193us/step - loss: 0.4799 - acc: 0.7785 - val_loss: 0.4228 - val_acc: 0.8134\n",
      "Epoch 40/100\n",
      "623/623 [==============================] - 0s 186us/step - loss: 0.5124 - acc: 0.7913 - val_loss: 0.4026 - val_acc: 0.8060\n",
      "Epoch 41/100\n",
      "623/623 [==============================] - 0s 193us/step - loss: 0.5114 - acc: 0.7833 - val_loss: 0.4404 - val_acc: 0.7836\n",
      "Epoch 42/100\n",
      "623/623 [==============================] - 0s 205us/step - loss: 0.4847 - acc: 0.7753 - val_loss: 0.4437 - val_acc: 0.8134\n",
      "Epoch 43/100\n",
      "623/623 [==============================] - 0s 238us/step - loss: 0.4943 - acc: 0.7881 - val_loss: 0.4479 - val_acc: 0.8060\n",
      "Epoch 44/100\n",
      "623/623 [==============================] - 0s 241us/step - loss: 0.4571 - acc: 0.8106 - val_loss: 0.4046 - val_acc: 0.8060\n",
      "Epoch 45/100\n",
      "623/623 [==============================] - 0s 204us/step - loss: 0.4694 - acc: 0.8042 - val_loss: 0.5001 - val_acc: 0.7836\n",
      "Epoch 46/100\n",
      "623/623 [==============================] - 0s 225us/step - loss: 0.5319 - acc: 0.7817 - val_loss: 0.4159 - val_acc: 0.7985\n",
      "Epoch 47/100\n",
      "623/623 [==============================] - 0s 178us/step - loss: 0.5546 - acc: 0.7512 - val_loss: 0.6557 - val_acc: 0.7388\n",
      "Epoch 48/100\n",
      "623/623 [==============================] - 0s 200us/step - loss: 0.5139 - acc: 0.7721 - val_loss: 0.3989 - val_acc: 0.8209\n",
      "Epoch 49/100\n",
      "623/623 [==============================] - 0s 186us/step - loss: 0.4677 - acc: 0.7945 - val_loss: 0.4000 - val_acc: 0.8209\n",
      "Epoch 50/100\n",
      "623/623 [==============================] - 0s 208us/step - loss: 0.4494 - acc: 0.8042 - val_loss: 0.4014 - val_acc: 0.8209\n",
      "Epoch 51/100\n",
      "623/623 [==============================] - 0s 228us/step - loss: 0.4463 - acc: 0.8042 - val_loss: 0.7049 - val_acc: 0.7537\n",
      "Epoch 52/100\n",
      "623/623 [==============================] - 0s 173us/step - loss: 0.4847 - acc: 0.7753 - val_loss: 0.4569 - val_acc: 0.8060\n",
      "Epoch 53/100\n",
      "623/623 [==============================] - 0s 194us/step - loss: 0.4942 - acc: 0.7801 - val_loss: 0.4611 - val_acc: 0.8060\n",
      "Epoch 54/100\n",
      "623/623 [==============================] - 0s 172us/step - loss: 0.4576 - acc: 0.8010 - val_loss: 0.4178 - val_acc: 0.8022\n",
      "Epoch 55/100\n",
      "623/623 [==============================] - 0s 181us/step - loss: 0.5350 - acc: 0.7721 - val_loss: 0.4947 - val_acc: 0.8172\n",
      "Epoch 56/100\n",
      "623/623 [==============================] - 0s 182us/step - loss: 0.4551 - acc: 0.7961 - val_loss: 0.4949 - val_acc: 0.8022\n",
      "Epoch 57/100\n",
      "623/623 [==============================] - 0s 250us/step - loss: 0.4799 - acc: 0.7897 - val_loss: 0.4299 - val_acc: 0.8097\n",
      "Epoch 58/100\n",
      "623/623 [==============================] - 0s 285us/step - loss: 0.4565 - acc: 0.8074 - val_loss: 0.3976 - val_acc: 0.8209\n",
      "Epoch 59/100\n",
      "623/623 [==============================] - 0s 190us/step - loss: 0.5287 - acc: 0.7737 - val_loss: 0.4106 - val_acc: 0.8209\n",
      "Epoch 60/100\n",
      "623/623 [==============================] - 0s 205us/step - loss: 0.4442 - acc: 0.7978 - val_loss: 0.4090 - val_acc: 0.8172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "623/623 [==============================] - 0s 220us/step - loss: 0.4668 - acc: 0.8090 - val_loss: 0.3984 - val_acc: 0.8246\n",
      "Epoch 62/100\n",
      "623/623 [==============================] - 0s 224us/step - loss: 0.4732 - acc: 0.7769 - val_loss: 0.5604 - val_acc: 0.7761\n",
      "Epoch 63/100\n",
      "623/623 [==============================] - 0s 210us/step - loss: 0.4565 - acc: 0.8010 - val_loss: 0.4146 - val_acc: 0.8209\n",
      "Epoch 64/100\n",
      "623/623 [==============================] - 0s 164us/step - loss: 0.4590 - acc: 0.8026 - val_loss: 0.3991 - val_acc: 0.8172\n",
      "Epoch 65/100\n",
      "623/623 [==============================] - 0s 168us/step - loss: 0.4705 - acc: 0.7897 - val_loss: 0.4222 - val_acc: 0.7985\n",
      "Epoch 66/100\n",
      "623/623 [==============================] - 0s 179us/step - loss: 0.4494 - acc: 0.8122 - val_loss: 0.4203 - val_acc: 0.8284\n",
      "Epoch 67/100\n",
      "623/623 [==============================] - 0s 165us/step - loss: 0.4985 - acc: 0.8042 - val_loss: 0.4062 - val_acc: 0.8209\n",
      "Epoch 68/100\n",
      "623/623 [==============================] - 0s 171us/step - loss: 0.4610 - acc: 0.8042 - val_loss: 0.4005 - val_acc: 0.8134\n",
      "Epoch 69/100\n",
      "623/623 [==============================] - 0s 177us/step - loss: 0.4585 - acc: 0.7897 - val_loss: 0.4383 - val_acc: 0.8209\n",
      "Epoch 70/100\n",
      "623/623 [==============================] - 0s 243us/step - loss: 0.4412 - acc: 0.8122 - val_loss: 0.4040 - val_acc: 0.8172\n",
      "Epoch 71/100\n",
      "623/623 [==============================] - 0s 189us/step - loss: 0.4455 - acc: 0.8106 - val_loss: 0.4388 - val_acc: 0.8060\n",
      "Epoch 72/100\n",
      "623/623 [==============================] - 0s 169us/step - loss: 0.4862 - acc: 0.7833 - val_loss: 0.4096 - val_acc: 0.8209\n",
      "Epoch 73/100\n",
      "623/623 [==============================] - 0s 169us/step - loss: 0.4769 - acc: 0.7961 - val_loss: 0.7898 - val_acc: 0.7687\n",
      "Epoch 74/100\n",
      "623/623 [==============================] - 0s 173us/step - loss: 0.4829 - acc: 0.7961 - val_loss: 0.4297 - val_acc: 0.8022\n",
      "Epoch 75/100\n",
      "623/623 [==============================] - 0s 190us/step - loss: 0.4294 - acc: 0.8058 - val_loss: 0.4017 - val_acc: 0.8209\n",
      "Epoch 76/100\n",
      "623/623 [==============================] - 0s 173us/step - loss: 0.4267 - acc: 0.8154 - val_loss: 0.4083 - val_acc: 0.8097\n",
      "Epoch 77/100\n",
      "623/623 [==============================] - 0s 166us/step - loss: 0.4319 - acc: 0.8138 - val_loss: 0.4479 - val_acc: 0.8134\n",
      "Epoch 78/100\n",
      "623/623 [==============================] - 0s 151us/step - loss: 0.4917 - acc: 0.7961 - val_loss: 0.3967 - val_acc: 0.8134\n",
      "Epoch 79/100\n",
      "623/623 [==============================] - 0s 143us/step - loss: 0.4658 - acc: 0.7881 - val_loss: 0.5808 - val_acc: 0.7873\n",
      "Epoch 80/100\n",
      "623/623 [==============================] - 0s 192us/step - loss: 0.4303 - acc: 0.8122 - val_loss: 0.4015 - val_acc: 0.8172\n",
      "Epoch 81/100\n",
      "623/623 [==============================] - 0s 246us/step - loss: 0.4468 - acc: 0.8074 - val_loss: 0.3957 - val_acc: 0.8209\n",
      "Epoch 82/100\n",
      "623/623 [==============================] - 0s 292us/step - loss: 0.4346 - acc: 0.8090 - val_loss: 0.4110 - val_acc: 0.8246\n",
      "Epoch 83/100\n",
      "623/623 [==============================] - 0s 199us/step - loss: 0.4171 - acc: 0.8202 - val_loss: 0.4334 - val_acc: 0.8172\n",
      "Epoch 84/100\n",
      "623/623 [==============================] - 0s 202us/step - loss: 0.4396 - acc: 0.8010 - val_loss: 0.4169 - val_acc: 0.8284\n",
      "Epoch 85/100\n",
      "623/623 [==============================] - 0s 197us/step - loss: 0.4364 - acc: 0.7945 - val_loss: 0.4005 - val_acc: 0.8172\n",
      "Epoch 86/100\n",
      "623/623 [==============================] - 0s 178us/step - loss: 0.4184 - acc: 0.8266 - val_loss: 0.4230 - val_acc: 0.8022\n",
      "Epoch 87/100\n",
      "623/623 [==============================] - 0s 169us/step - loss: 0.4245 - acc: 0.8202 - val_loss: 0.4055 - val_acc: 0.8284\n",
      "Epoch 88/100\n",
      "623/623 [==============================] - 0s 190us/step - loss: 0.4631 - acc: 0.7961 - val_loss: 0.4296 - val_acc: 0.8022\n",
      "Epoch 89/100\n",
      "623/623 [==============================] - 0s 208us/step - loss: 0.5149 - acc: 0.7978 - val_loss: 0.5373 - val_acc: 0.7761\n",
      "Epoch 90/100\n",
      "623/623 [==============================] - 0s 234us/step - loss: 0.5148 - acc: 0.7913 - val_loss: 0.3994 - val_acc: 0.8209\n",
      "Epoch 91/100\n",
      "623/623 [==============================] - 0s 186us/step - loss: 0.4253 - acc: 0.8250 - val_loss: 0.4392 - val_acc: 0.7985\n",
      "Epoch 92/100\n",
      "623/623 [==============================] - 0s 194us/step - loss: 0.4266 - acc: 0.8186 - val_loss: 0.4418 - val_acc: 0.8433\n",
      "Epoch 93/100\n",
      "623/623 [==============================] - 0s 171us/step - loss: 0.4464 - acc: 0.8074 - val_loss: 0.3991 - val_acc: 0.8209\n",
      "Epoch 94/100\n",
      "623/623 [==============================] - 0s 201us/step - loss: 0.4180 - acc: 0.8186 - val_loss: 0.4200 - val_acc: 0.8022\n",
      "Epoch 95/100\n",
      "623/623 [==============================] - 0s 178us/step - loss: 0.4538 - acc: 0.7961 - val_loss: 0.4052 - val_acc: 0.8209\n",
      "Epoch 96/100\n",
      "623/623 [==============================] - 0s 162us/step - loss: 0.4352 - acc: 0.8090 - val_loss: 0.4549 - val_acc: 0.7910\n",
      "Epoch 97/100\n",
      "623/623 [==============================] - 0s 197us/step - loss: 0.4280 - acc: 0.8090 - val_loss: 0.4060 - val_acc: 0.8172\n",
      "Epoch 98/100\n",
      "623/623 [==============================] - 0s 170us/step - loss: 0.4464 - acc: 0.8074 - val_loss: 0.5409 - val_acc: 0.7948\n",
      "Epoch 99/100\n",
      "623/623 [==============================] - 0s 160us/step - loss: 0.4344 - acc: 0.8122 - val_loss: 0.4471 - val_acc: 0.7985\n",
      "Epoch 100/100\n",
      "623/623 [==============================] - 0s 191us/step - loss: 0.4277 - acc: 0.8090 - val_loss: 0.4512 - val_acc: 0.8097\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 0.8656 - acc: 0.6083 - val_loss: 0.6194 - val_acc: 0.6418\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 187us/step - loss: 0.6709 - acc: 0.6372 - val_loss: 0.5746 - val_acc: 0.7239\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 174us/step - loss: 0.6161 - acc: 0.6806 - val_loss: 0.5609 - val_acc: 0.7313\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 164us/step - loss: 0.6621 - acc: 0.6404 - val_loss: 0.5323 - val_acc: 0.7313\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 161us/step - loss: 0.7083 - acc: 0.6565 - val_loss: 0.7407 - val_acc: 0.7351\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 188us/step - loss: 0.7703 - acc: 0.6677 - val_loss: 0.5419 - val_acc: 0.7313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1fb96b70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=30, callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep\n",
    "input_shape = (10,)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2af7eb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep\n",
    "n_cols = 10\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b435780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target,\n",
    "                               epochs=20, validation_split=0.4,\n",
    "                               callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target,\n",
    "                               epochs=20, validation_split=0.4,\n",
    "                               callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Capacity\n",
    "Experiment. Start small e.g. 1 hidden layer with 100 nodes. Then keep making it bigger - e.g. 1,250, 2,250, 3,200 then when the validation score reduces, try a slightly smaller model than the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2001, 784), (2001, 10))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data prep\n",
    "from urllib.request import urlretrieve\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "file = 'mnist.csv'\n",
    "url = 'https://assets.datacamp.com/production/course_1975/datasets/' + file\n",
    "urlretrieve(url, file)\n",
    "df = pd.read_csv(file, header=None)\n",
    "\n",
    "X = df.iloc[:, 1:].as_matrix()\n",
    "y = to_categorical(df.iloc[:,0].as_matrix())\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_div_255 = X / 255.0\n",
    "\n",
    "(X_scaled.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,100].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(df.iloc[:,0])[:,9].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.        , -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.03528118,\n",
       "        -0.0505039 , -0.05140922, -0.05371599, -0.04466228, -0.02977679,\n",
       "        -0.02240012, -0.02243459, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.0224653 , -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.03642003, -0.05565053, -0.07928351, -0.10275288, -0.11443913,\n",
       "        -0.11538942, -0.13185808, -0.13820836, -0.13389915, -0.12955383,\n",
       "        -0.10766918, -0.09111253, -0.06944051, -0.05385637, -0.02899263,\n",
       "        -0.02475644, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02257605,\n",
       "        -0.02304496, -0.03582383, -0.06238847, -0.09499971, -0.13511372,\n",
       "        -0.16366661, -0.20077792, -0.22819789, -0.24687707, -0.26073946,\n",
       "        -0.27152508, -0.26662706, -0.23131083, -0.18468006, -0.14309826,\n",
       "        -0.11837656, -0.0847948 , -0.04476069, -0.03107843, -0.0223976 ,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.0310608 , -0.03575446, -0.06685463, -0.11660869,\n",
       "        -0.15937525, -0.20991932,  1.03755805,  2.25788319,  1.85891281,\n",
       "         2.30378966,  2.61763474,  1.67455724, -0.20940715, -0.47807246,\n",
       "        -0.43926797, -0.3625194 , -0.28531436, -0.22109758, -0.15895708,\n",
       "        -0.10297725, -0.06875372, -0.03924276, -0.02238925, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.04801974,\n",
       "        -0.0867583 , -0.13089386, -0.18304169,  0.02197307,  2.64148509,\n",
       "         2.92330508,  2.43449956,  2.07237169,  1.77846539,  1.59981248,\n",
       "         1.5231541 ,  1.17657811, -0.63045159, -0.66158001, -0.55884126,\n",
       "        -0.44730466, -0.35700142, -0.27594207, -0.20156131, -0.13656663,\n",
       "        -0.07517727, -0.03826298, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02825751, -0.03661369, -0.07284488, -0.13013977, -0.19062681,\n",
       "        -0.25851298,  1.97047786,  2.80081657,  2.2010727 ,  1.76669702,\n",
       "         1.45948472,  0.66591431,  0.25864282,  0.93629831,  1.18188251,\n",
       "         0.60855357, -0.81891927, -0.71499074, -0.58203394, -0.46456225,\n",
       "        -0.3542358 , -0.26172599, -0.17735425, -0.11326479, -0.05011527,\n",
       "        -0.02236068, -0.02236068, -0.0225114 , -0.03840962, -0.05930025,\n",
       "        -0.11623378, -0.1772863 , -0.25209024, -0.33581154,  2.58279328,\n",
       "         2.24692662,  1.36678806,  0.31415221, -0.57437363, -1.14509606,\n",
       "        -1.21996203, -1.245552  ,  0.4728261 ,  1.16441382, -0.2792731 ,\n",
       "        -0.84406621, -0.69315209, -0.5440715 , -0.4190482 , -0.304594  ,\n",
       "        -0.2066172 , -0.13104658, -0.05621853, -0.02236068, -0.02236068,\n",
       "        -0.02237843, -0.04311051, -0.09219324, -0.1440088 , -0.2032178 ,\n",
       "        -0.28547451, -0.3811377 ,  1.79987151,  1.38389992, -0.35133001,\n",
       "        -0.98840373, -1.09682577, -1.14875492, -1.13211532, -1.12909534,\n",
       "        -1.11687496,  0.77044543,  0.76641312, -0.89041426, -0.73239328,\n",
       "        -0.59322275, -0.4460633 , -0.3198386 , -0.20553046, -0.13481522,\n",
       "        -0.04937964, -0.02236068, -0.02236068, -0.02458125, -0.05487604,\n",
       "        -0.09442717, -0.15022003, -0.21268961, -0.29479405, -0.41036157,\n",
       "        -0.37065867, -0.61545767, -0.89104227, -0.99809645, -1.01491304,\n",
       "        -0.97003423, -0.9164925 , -0.93205415, -0.96700451, -0.1774229 ,\n",
       "         1.21182327, -0.52569044, -0.7373967 , -0.5880315 , -0.43463662,\n",
       "        -0.29659736, -0.18092905, -0.10976216, -0.05101854, -0.02240321,\n",
       "        -0.02236068, -0.03267454, -0.05475533, -0.08986007, -0.14702648,\n",
       "        -0.21284925, -0.31705587, -0.43709471, -0.59190598, -0.77230733,\n",
       "        -0.90189352, -0.93732771, -0.8830624 , -0.81029759, -0.78372159,\n",
       "        -0.80769269, -0.87160353, -0.4941667 ,  1.35450328, -0.21213777,\n",
       "        -0.69169652, -0.53419338, -0.38958329, -0.27541585, -0.15035005,\n",
       "        -0.07314759, -0.03413367, -0.02240324, -0.02236068, -0.03159275,\n",
       "        -0.04593447, -0.08067613, -0.13779743, -0.21239125, -0.32804489,\n",
       "        -0.46076064, -0.63342654, -0.79496406, -0.88931613, -0.87502702,\n",
       "        -0.79855451, -0.74628321, -0.75224716, -0.7933022 , -0.89864664,\n",
       "         0.37924144,  1.33008981, -0.18136489, -0.64045163, -0.4919011 ,\n",
       "        -0.36493073, -0.26012451, -0.15143158, -0.06311241, -0.02262986,\n",
       "        -0.02236068, -0.02236068, -0.03007034, -0.03971676, -0.06939412,\n",
       "        -0.13474454, -0.22194523, -0.34709393, -0.49357633, -0.66922592,\n",
       "        -0.81994794, -0.88300857, -0.854984  , -0.7844564 , -0.78841922,\n",
       "        -0.82416171, -0.91848464, -0.84429039,  1.06311449,  1.29983373,\n",
       "        -0.13684987, -0.59846059, -0.4686255 , -0.34998863, -0.26002444,\n",
       "        -0.1571529 , -0.05770468, -0.02317184, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.05970811, -0.13682882, -0.24029765,\n",
       "        -0.36889462, -0.52872363, -0.6876136 , -0.82202604, -0.87851178,\n",
       "        -0.85287677, -0.84160725, -0.91253642, -0.99385072, -1.10569136,\n",
       "         0.67770757,  1.10683833,  0.93852408, -0.70475315, -0.57459494,\n",
       "        -0.44140091, -0.34550854, -0.25734472, -0.15845218, -0.06667788,\n",
       "        -0.02240034, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.06446192, -0.13321936, -0.26825543, -0.39695424, -0.53770735,\n",
       "        -0.69343786, -0.82098131, -0.86929641, -0.87861657, -0.9178003 ,\n",
       "        -1.05909734, -0.92847871,  0.36077261,  1.04365668,  1.06790494,\n",
       "        -0.12415095, -0.75828595, -0.58450807, -0.45446845, -0.36563238,\n",
       "        -0.26481699, -0.16184461, -0.08012259, -0.02242572, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.06451329, -0.14282276,\n",
       "        -0.28540229, -0.41307748, -0.53308674, -0.66330208, -0.78064268,\n",
       "        -0.85744589, -0.89653667, -0.97819567, -0.51714869,  0.90538433,\n",
       "         1.0250636 ,  1.07157362,  0.98346495, -0.67599107, -0.73121103,\n",
       "        -0.59682838, -0.47302215, -0.37407644, -0.26263001, -0.16893031,\n",
       "        -0.07750615, -0.02242769, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.06733417, -0.16277014, -0.30153972, -0.42005715,\n",
       "        -0.53141394, -0.64147201, -0.74627607, -0.80260285, -0.85034158,\n",
       "        -0.75822753,  0.76089791,  1.09317372,  1.10740998,  0.75504564,\n",
       "        -0.58169873, -0.88844619, -0.726514  , -0.59955222, -0.47406252,\n",
       "        -0.36632361, -0.25152162, -0.17082324, -0.07872702, -0.03135294,\n",
       "        -0.02304856, -0.02236068, -0.02249207, -0.02236068, -0.06593526,\n",
       "        -0.17403803, -0.31500407, -0.42014136, -0.51719086, -0.60409367,\n",
       "        -0.69100964, -0.74199714, -0.78809351,  0.99823366,  1.30569511,\n",
       "         1.21369262,  0.28884307, -0.94494112, -0.9441887 , -0.84537668,\n",
       "        -0.72251196, -0.59407639, -0.46128506, -0.35663025, -0.25128178,\n",
       "        -0.1665539 , -0.07595607, -0.03429014, -0.02244635, -0.02236068,\n",
       "        -0.03108685, -0.02251259, -0.07840006, -0.19870027, -0.32703194,\n",
       "        -0.42649542, -0.5152619 , -0.57438002, -0.65447977, -0.6048382 ,\n",
       "         0.66698727,  1.55337784,  1.36497105,  0.32544497, -0.89047125,\n",
       "        -0.99904309, -0.94075293, -0.84639233, -0.71477409, -0.57214159,\n",
       "        -0.44208801, -0.34235101, -0.24814364, -0.16187718, -0.07528784,\n",
       "        -0.02780164, -0.02236068, -0.02236068, -0.02251243, -0.03037786,\n",
       "        -0.09254247, -0.21441516, -0.32995313, -0.43589282, -0.52711414,\n",
       "        -0.60646608, -0.68287949,  0.10553333,  1.54622565,  1.48651123,\n",
       "         0.62108774, -1.00724945, -0.74515015,  0.10384474,  0.31311583,\n",
       "         0.39179339, -0.68784065, -0.53178989, -0.41096416, -0.30813482,\n",
       "        -0.22154657, -0.13212236, -0.06799871, -0.024937  , -0.02310466,\n",
       "        -0.02236068, -0.02236068, -0.04626824, -0.10596859, -0.21546745,\n",
       "        -0.32204638, -0.44409597, -0.55326888, -0.65522897,  0.23685318,\n",
       "         1.43755429,  1.36488204,  1.34179545, -0.13298473,  0.99602321,\n",
       "         1.1577951 ,  1.23515876,  1.39115931,  1.62779105,  0.93498348,\n",
       "        -0.47634251, -0.35846115, -0.26279628, -0.19121345, -0.1124221 ,\n",
       "        -0.05708199, -0.0254811 , -0.02256111, -0.02236068, -0.02236068,\n",
       "        -0.03589223, -0.09971338, -0.19670458, -0.29530664, -0.4149226 ,\n",
       "        -0.53926955,  0.14089131,  1.45508826,  1.35037774,  1.2535714 ,\n",
       "         1.18605803,  1.11792829,  1.09791853,  1.15765411,  1.30579403,\n",
       "         1.31196518,  1.44229459,  1.85273549, -0.39170633, -0.2922077 ,\n",
       "        -0.21393539, -0.15039882, -0.08429269, -0.05178589, -0.02247019,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02680701, -0.08642491,\n",
       "        -0.15832553, -0.24301123, -0.35672667, -0.47929025,  1.04898137,\n",
       "         1.62606255,  1.36849823,  1.23931548,  1.17841727,  1.14967824,\n",
       "         1.10254963,  0.49432336,  0.47404046, -0.35865611, -0.51170402,\n",
       "        -0.39261569, -0.29910077, -0.2280297 , -0.16637447, -0.11407468,\n",
       "        -0.05587397, -0.03150759, -0.0234373 , -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02241986, -0.04624667, -0.10329796, -0.18180977,\n",
       "        -0.26565084, -0.36933286,  1.43441577,  2.01274132,  1.70962546,\n",
       "         1.48944272,  1.39589912,  0.4887934 , -0.46304153, -0.72881331,\n",
       "        -0.60805007, -0.49257663, -0.37181893, -0.27484081, -0.21086026,\n",
       "        -0.14724681, -0.10779726, -0.07349634, -0.03115272, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02991516,\n",
       "        -0.03428449, -0.06222545, -0.1063876 , -0.17222562, -0.2443069 ,\n",
       "        -0.32626641, -0.40740969, -0.47226471, -0.52807449, -0.5612891 ,\n",
       "        -0.54907808, -0.51261328, -0.45947018, -0.39080748, -0.32410207,\n",
       "        -0.25631726, -0.18864598, -0.13808341, -0.08540417, -0.07074562,\n",
       "        -0.04931226, -0.03146963, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.03190129,\n",
       "        -0.06278224, -0.09853336, -0.1351974 , -0.18648461, -0.23098176,\n",
       "        -0.27261298, -0.30843128, -0.31681196, -0.30135709, -0.29066756,\n",
       "        -0.26667058, -0.24117945, -0.21208314, -0.15559788, -0.12429553,\n",
       "        -0.08797441, -0.05664356, -0.05210408, -0.03211333, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.03007808, -0.03382028, -0.05678775,\n",
       "        -0.07776211, -0.10507534, -0.11887378, -0.16117245, -0.17627604,\n",
       "        -0.18239771, -0.17907111, -0.17815193, -0.15005324, -0.1322527 ,\n",
       "        -0.10806241, -0.0829328 , -0.0513392 , -0.04114933, -0.03182944,\n",
       "        -0.03184012, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.0225016 , -0.02241701, -0.02242659, -0.02683111, -0.02251049,\n",
       "        -0.02251074, -0.03480849, -0.04519129, -0.05205432, -0.05685638,\n",
       "        -0.05187646, -0.03794469, -0.03501572, -0.03357846, -0.02250047,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068, -0.02236068,\n",
       "        -0.02236068, -0.02236068, -0.02236068, -0.02236068]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y[4,:], X_scaled[4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with unscaled data (awful!)\n",
    "model_unscale = model.fit(X, y, validation_split=0.3, epochs=20, verbose=False)\n",
    "model_div_255 = model.fit(X_div_255, y, validation_split=0.3, epochs=20, verbose=False)\n",
    "model_ss      = model.fit(X_scaled, y, validation_split=0.3, epochs=20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2effa080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.plot(model_unscale.history['val_loss'], 'r',\n",
    "         model_div_255.history['val_loss'], 'b',\n",
    "         model_ss.history['val_loss'], 'g')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div 255 for the win... it's intersting the impact negative values have when there are relu's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
